# Assembling the lesson

* Picking a dataset
* Formatting a dataset to make it a teaching dataset
* How to write exercises (you)
* Different types of exercises and why / how to use them
* How to test exercises for correct level
* How to space exercises
* Writing the live code (we)
* What to write for instructor notes
* Writing the narrative around the code (I)
* How to evaluate lesson drafts for expert blind spot, correct leveling and scope
* Issue Bonanza (limited - CAC?)
* Clean-up (authors and staff)
* Put workshop page together
* We now have the alpha version of the lesson. (?)

---

## Picking a dataset

The dataset is a critical element of The Carpentries lessons. It needs to be chosen carefully and meet the following criteria.

1. **Use a single dataset** -- Workshops are domain-specific and the same dataset should be used across all lessons that are part of the same workshop. When developing a lesson that is not part of a standalone workshop, we encourage you to choose a dataset that is already in use in one of the workshops. If needed, you may want to create subsets of the main dataset that can include modifications. For instance, to illustrate the principles of tidy data in the Data Carpentry Ecology Spreadsheet lesson, messy spreadsheets are created from the original dataset. They use the same variables and observation types as the original dataset. Whenever possible, create these derived datasets using scripts rather than by hand, so they can be regenerated if the original dataset changes.

1. **The dataset should be released under a CC0 license** -- Copyright laws and laws governing use and sharing of data and databases vary among countries. The Creative Commons Zero license is designed to allow unrestricted use and sharing of data universally. The CC0 license allows the development of lessons around the dataset and modification of the dataset to suit our teaching needs.

1. **The datasets should be deposited in a public repository** -- We typically use Figshare. If you choose another option, make sure that the repository where the data is archived should have the following features: 
   - a DOI link points to an overview of the dataset
   - pre-registration of the DOI
   - all files can be downloaded directly as an archive (e.g., zip file) with a persistent link
   - each file can be downloaded directly with a persistent link
   - the repository supports versioning


1. **The dataset should be real and represent what researchers in the field encounter** -- Our workshops should provide an authentic experience. The datasets used as examples in the lessons should be based on real research datasets, and be of sufficient complexity that they are representative of the type of dataset that learners would encounter in their own research.

1. **Authors of the dataset should be identifiable, acknowledged, and there should be a link to the original source for the data** -- Even though the dataset we use in the lessons are released under a CC0 license, we want to acknowledge the authors of the dataset and link to the research projects based on the data we use.

1. **The dataset should be large enough** -- It should represent a real challenge that highlights the power and usefulness of the tools covered in the lessons. The dataset should be larger than what would be easy to analyze and manipulate in a spreadsheet program. For instance, the main Data Carpentry Ecology lesson dataset has ~35,000 rows.

1. **The dataset should be complex enough to ask interesting questions** -- Each observation should have at least 4-5 variables for each observations. These variables should be of a few different data types (at least continuous, discrete, integers, real numbers; and depending on the domain, include more specialized data types such as date/time, GPS coordinates, unstructured text, etc.)

1. **The motivation for study and the protocol for data collection should be understable without much context** -- We have limited time in our workshops to cover the technical skills we want to teach. It should not take long to explain learners what the data is about, how it was collected, and interesting questions that can be asked from it.

1. **The dataset should be relevant in different geographies and cultural contexts** -- Our workshops are taught to learners from diverse cultural backgrounds. The dataset should be understood without much context or pre-requiste knowledge to find it compelling.

1. **There should be clear and comprehensive metadata** -- The metadata should include a description of the data, and covers what is included in each column, how it was measured, and the unit in which it is reported.

Overall, datasets we use in our teaching examples should be examples of publicly deposited data suitable for research re-use. Learners should be able to use these datasets as examples and guides for their own research data that they would like to publish and make available to the community.


## Formatting the dataset for teaching

A possible challenge when using research datasets for teaching is that the dataset can include complexity that make teaching more difficult. While it is important that the dataset provides an authentic experience to learners, you may want to consider simplifying it or doing some initial data cleaning and wrangling to make teaching easier. For instance, you may want to edit the dataset such that missing values are parsed as such when they are imported in R using the default values of the function used (e.g., `readr::read_csv()` considers empty cells and "NA" as default values for missing data). You may also want to consider removing data leading to errors or warnings during parsing, columns with data types that are not relevant for the learning objectives of the workshops, or variables for which the protocol used is difficult to explain.

When preparing a dataset for teaching, aim to find the balance between providing an authentic experience to learners while keeping complexity low to limit distractions from the learning objectives. Depending on the lesson's goals, it might also be interesting to include several versions of the datasets that have undergone various levels of processing. At the beginning of the lesson, you can provide clean and well organized dataset, while later you can introduce more complexity and teach how to handle it to generate the cleaner version of the data. Don't introduce too many (no more than 3) versions of the datasets in your lessons, as dealing with many files and remembering their differences can become challenging for the learners.


## Overview 

Carpentries workshops last two full days. Generally workshops run from 9am to 5pm, with 30-minute breaks in the morning and in the afternoon, and an hour lunch break, leaving 6 hours for instruction. Carpentries lessons are therefore designed to be taught in 1.5, 3 or 6 hours. Having long and regular breaks are needed to pace the instruction, and allow learners to remain focused and engaged.

Lessons are divided into episodes. Each episode should:

- be designed to last 15-30 minutes;
- limit cognitive load by introducing at most 7($\pm$ 2) new concepts (3 to 5 concepts preferred);
- include at least one to three exercises that let learners practice the concepts covered in the episode.


## Designing exercises

Once the learning objectives for the lesson and each episode have been identified, you can start designing exercises that provide learners an opportunity to practice the skills outlined in the learning objectives. The Bloom taxonomy level of the learning objectives help frame how much information should be provided to the learners to be able to complete the exercise and the type of exercise. Writing the exercises before writing the content of the lesson ensures that the lesson will remain focused, and can reveal concepts needed to solve the exercises that were not previously considered.

Starting with two to four exercises you want learners to be able to complete on their own at the end of the training, will help you identify the skills they need to acquire. Creating this list of skills will guide you in assembling your learning objectives. This list, in combination with the learners' profiles, and the time you have available in your training, will help you identify the prerequisite skills for the audience of the workshop, and determine at which level of the Bloom taxonomy the learning objectives need to be written. This approach is "meet your learners where they are". [FIXME: this paragraph might belong better to the learning objective section].

Identifying what the final exercises look like, and the skill they require, will also help you create the narrative for your lessons. The final exercises should be designed such that the learners can understand from the beginning of the lesson what they are working towards. The intermediate exercises can then be designed to build the skills and confidence learners need to be able to solve the final exercises. While lessons should include exercises that are direct applications of the skills covered in the instructions, at least half of the exercises should provide an opportunity for learners to integrate these new skills with skills covered earlier in the lesson. Learning is reinforced when Instructors explicitly point out how the skills seen in earlier parts of the lesson are being integrated to solve the exercises.

Exercises in Carpentries lessons are a form of formative assessment. They help learners further their learning by having a chance to put into practice the skills being taught. They also help Instructors monitor the level of understanding in the classroom, and potentially catch misconceptions in the learner's mental models that can be corrected early on.

## The different types of exercises

### Multiple Choice Questions

Multiple choice questions can be an useful tool in formative assessment if the incorrect answers help you identify misconceptions. Designing MCQs with informative distractors takes time. It can also be challenging to identify useful distractors a priori (expert blindspot), appropriate answers for the MCQ may be prompted by teaching experience and may need to be refined. Don't test for too many concepts at once. Ask learners if they came up with other solutions, or thought of other ways of approaching the problem (that end up not working).

a. 
```{r, echo=TRUE, eval=FALSE}
iris %>%
  filter(Species == "setosa" & Petal.Length > 1.5) %>%
  select(Species, Petal.Width)
```
b.
```{r, echo=TRUE, eval=FALSE}
iris %>%
  select(Species == "setosa" & Petal.Length > 1.5) %>%
  filter(Species, Petal.Width)
```
c.
```{r, echo=TRUE, eval=FALSE}
iris %>%
  select(Species, Petal.Width)  %>%
  filter(Species == "setosa" & Petal.Length > 1.5)
```

The distribution of the answers can also help you strategize how to address the misconceptions.


### Parsons Problem

### Fill in the blanks

### Switch the dataset

### Use the concept in a different context
