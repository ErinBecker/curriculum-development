[
["index.html", "The Carpentries Curriculum Development Handbook Chapter 1 Work in progress", " The Carpentries Curriculum Development Handbook François Michonneau 2019-01-16 Chapter 1 Work in progress This is work in progress. Comments and suggestions are welcome either as: an issue or a pull request on the GitHub repository or using hypothes.is "],
["conceptual-elements.html", "Chapter 2 Conceptual elements 2.1 The Carpentries mindset to curriculum development 2.2 Backward and Learner-centered lesson design 2.3 Creating a narrative and selecting a dataset 2.4 Limitations of our approach 2.5 The structure of our curriculum 2.6 Collaborative lesson design", " Chapter 2 Conceptual elements The Carpentries mindset to curriculum development - evidence-based curriculum development What are the core pedagogical concepts that are part of a Carpentry lesson? Teach most useful first motivation What are the goals of a Carpentries lesson and how do we achieve them increased confidence in the tools we teach Self-directed learning The open source model of development adapted for lesson Collaborative lesson development. Writing lessons for others to use Backwards lesson development / learner centered design Formative assessment Lesson structure - workshop / lesson / episode / challenge What to consider when selecting a dataset The I, We, You model The idea of having a narrative to the lesson 2.1 The Carpentries mindset to curriculum development Developing a Carpentry curriculum is based on the results of research in the science of learning and the science of teaching. We rely on the findings synthesized in the Ambrose et al. book “How learning works”. We recommend this book as part of our Instructor training, so Instructors can understand why we teach the way we do, and why our lessons are designed the way they are. The authors identify 7 principles (direct quotation from the book in bold): “Students’ prior knowledge can help or hinder learning.” – Identifying what the learners know before coming to our workshops help us adjust what we teach. One way we do this is through our pre-workshop surveys. Regular challenges throughout our lessons help Instructors and Learners identify misconceptions. “How students organize knowledge influences how they learn and apply what they know.” – We aim to design our lessons in chunks (the episodes) that contain about 7 key concepts (+/- 2). This is about the maximum amount of information that can be held in short-term memory. These chunks should not contain more information in order for learners to have an opportunity to practice how to use these new concepts, how they are related to each others, how they can be integrated with previously covered concepts. Chunking allows Learners to have a chance to organize effectively this new knowledge, increasing the likelihood of being retrieved successfully in new contexts. “Students’ motivation determines, directs, and sustains what they do to learn.” – Our Learners are motivated to learn the concepts taught in our workshops. They realize they need the skills we teach to conduct their research more effectively. They have experienced the pain that comes with copying and pasting data across spreadsheets, or having to re-do complex graphs over and over as new data come in. However, they may also be intimidated by how much they have to learn before being proficient programmers and data analysts. Two of our strategies to motivate our Learners are: (1) to create a positive learning environment, and (2) to teach the most useful skills first. We cover the former in Instructor Training, the latter below. “To develop mastery, students must acquire component skills, practice integrating them, and know when to apply what they have learned.” – For Learners to master the skills we teach in our workshops, we include opportunities for them to practice through our challenges. When designing our lessons, we need to identify all the skills that are needed to answer these challenges, and design them to incrementally combine the skills we teach. Well-designed challenges contribute to our Learner’s ability to transfer the skills they acquire in our workshop to their own research. “Goal-directed practice coupled with targeted feedback enhances the quality of students’ learning.” – [this paragraph needs to be rewritten/re-thought; it doesn’t cover the skill of being able to recognize an answer that might be wrong/incorrect]. When Learners try to solve the challenges we include in our lessons they receive direct feedback from the computer. Either they get an error message or the expected answer. The negative feedback from error message does not inform learners on their learning process. They can also be frustrating and demotivating. When designing challenges to be included in the lessons, completing them successfully should provide direct positive feedback to the students that they are acquiring the skills that are being taught in the workshop. To do so, challenges should be formulated to only use skills that have already been introduced during the workshop, and with a limited range of possible answers. “Students’ current level of development interacts with the social, emotional, and intellectual climate of the course to impact learning.” – A workshop’s positive environment makes our learners thrive and is more likely to increase their confidence in their ability to use the skills we teach. Creating a positive environment is a shared responsibility between all participants: Instructors, Helpers, and Learners. Setting up expectations by having and enforcing our Code of Conduct contributes to making the workshop space welcoming for everyone. Other strategies that the Carpentries use such as the green sitckies, are outlined in Instructor Training. When it comes to the content for the curriculum, creating a positive environment means that examples chosen cannot be alienating, that the skill level is appropriate for the audience, and the examples and challenges are leading to outcomes with direct applications for our learners. For instance, when one of our Learners achieve to create a visualization that they can directly apply on their own data, it reinforces their motivation in the topic and favors a positive climate. “To become self-directed learners, students must learn to monitor and adjust their approaches to learning.” – In-person workshops allow Instructors to model the thinking process that is needed to address the challenges that are included in our lessons. As an Instructor, being very explicit (“thinking aloud”) about the steps of the mental model that are involved in identifying the functions to use, the values of the arguments they take, and the order in which to call these functions to solve a challenge, will help learners think of the questions they will need to ask themselves when facing new problems to solve. While this type of approach works for any level of complexity in the challenges we teach, it works best for most advanced ones, where several steps need to be integrated to come to the solution. Before reaching this level of complexity, the challenges can be designed to guide this process, using scaffolding. Scaffolding is the process where all the pieces of code to answer the problem are already written but are not in the correct order (Parson’s problem), or fill in the blanks. This might be one of the most important things we teach in our workshops. It can set up Learners to a successful path to self-learning. When developing the content of the curriculum, think of the kind of thinking process that is needed to successfully address the research questions in your field. In the context of a 2-day workshop, not all of the principles outlined by the authors of “How Learning Works” apply. We emphasize those that create a positive, engaging experience for our participants, and that will motivate them to learn more about the best practices and skills covered in our workshops. Applying these principles require an effective commbination of how the lessons are taught (delivery) and what is included in the lessons (content). Most of aspects regarding how we deliver workshops are outlined in our Instructor Training. Before diving into creating lesson content, we recommend that you familiarize yourself with some of the concepts included in our Instructor Training curriculum. In this handbook, we focus on how to design the content of our workshops. 2.2 Backward and Learner-centered lesson design Analogy with drawing: you want to draw the outline before filling the details. We use a backward lesson design: We identify the practical skills we aim to teach. We design challenges to give an opportunity for our learners to practice and integrate these skills. We identify what we need to teach for our learners to acquire these skills. Using this approach ensures that all the skills we teach work together to meet the over-arching goal of our lesson and our curriculum. It also limits the risk of not teaching a concept needed to be able to master the skills we aim to teach. Similarly, it avoids teaching topics that do not help us meet our goals. Reducing distractions is part of our lesson design as we strive to reduce cognitive load on learners. To this end, we also develop our lessons to be centered around a narrative and a dataset they can relate with quickly. Because our workshops are domain-specific, the data we use, and the type of questions we ask with the data are already somewhat familiar to our learners. Their energy and focus can be directed towards learning the skills we teach rather than getting familiar with data and concepts that are foreign to them. This strategy also increases the motivation of our learners. By learning how to solve problems that are familiar to them, they can more easily transpose these skills directly to their own data, and make a good starting point to continue their learning process as they try to solve new or more complex problems with their own data. 2.2.1 How to identify the practical skills? Above all, in a Carpentries workshop, our aim is to increase the confidence of our Learners. We want to demystify and make accessible the process of computing and analyzing data. A fraction of people attending our workshops have little to no coding experience. Attending an in-person workshop provides an opportunity to try, in a friendly-environment, something they perceive as intimidating. [FIXME Does Kari have data on this?] Another important goal is to make the research life of our learners easier. We emphasize best practices. The kind of skills that are difficult to learn from a Google search. Teaching defensive programming, how to use spreadsheets effectively, or how to organize files consistently across research projects, are practical skills that can save a lot time when learners apply them in their own research. When deciding what to teach, try to identify the skills that are the most useful and have the highest impact first. Having domain-specific workshops has the advantage that we can adapt the content of the workshops to reflect what the most useful and high-impact skills are for each domains. The lessons should be designed to create frequent opportunities for Learners to practice the skills taught while exemplifying the tasks they perform in their daily research lives. Live coding and hands-on challenges that Learners can directly relate to should allow them to project how they can start using the skills taught with their own data as soon as the workshop is over. Teaching the most useful in a practical way aims at encouraging continued learning after attending a workshop. Additionally, we have found that having local communities created by Instructors and Learners, provide a resource and support group that fosters this culture of continuous and continued learning. As you are planning the design of your lesson material identify: Which skills do I use daily in my research workflow? Which skills do I use in combination/do I integrate to perform common tasks? What are the specificities of the data, datasets, and metadata used in my research? What are the tools, libraries, packages that are typical of my domain? What is the life cycle of my data: How is the data transformed and analyzed from acquisition to publication and archival? As an expert in your field, there might be mutliple steps involved in your analysis that you have become so used to, that you might not recognize them as separate steps (expert blind spot, fluid representation). When designing the content of your lesson and curriculum, it is crucial that you identify these intermediate steps that will need to be taught to novices in the field. It is also however important when building the lesson to organize the content to put useful and applicable examples as early as possible. We have found that in the context of a 2-day workshop, starting with teaching how to generate high-quality plots before teaching about data types leads to more motivated Learners than doing the opposite. 2.2.2 How to design challenges to assess understanding? 2.2.3 How to plan for the content of the lesson? 2.3 Creating a narrative and selecting a dataset 2.4 Limitations of our approach We don’t teach Learners to be experts in 2 days, some of the complexity that comes with expertise can’t be part of our workshop. We do aim to set up the mental model of our Learners to allow them to grow into experts in the future. Managing this expectation is important because it limits demotivation. 2.5 The structure of our curriculum 2.5.1 The elements of The Carpentries Curriculum 2.5.1.1 Episodes An episode teaches one concept. It has learning objectives and exercises that “test” understanding of those learning objectives, essentially with summative assessment. Episodes can be used independently from each other, but often draw concepts from other episodes. 2.5.1.2 Lesson A lesson is a set of episodes that teaches a group of related concepts with a particular goal. There is a “landing page” for the lesson that has a list of all the episodes as well as the overall learning objectives. Within a lesson, episodes should be linked together. The lesson should have learning objectives that are met by the episodes, or by linking the concepts across episodes. Assessment of outcomes is more summative, potentially in an after-workshop survey. (We don’t necessarily have a way of ‘testing’ lesson-level learning objectives). Lessons can be used independently and should not rely on concepts from other lessons. A lesson can be constructed in a variety of ways, by adding or removing episodes related to that lesson. However, there should be a clear recommended structure or structures. 2.5.1.3 Workshop A workshop is a set of connected lessons. The workshop should have goals and objectives. Objectives are evaluated in pre- and post-workshop surveys. (Although actually we don’t do this so much right now, but that’s ok). A workshop may have a narrative structure, explicitly linking lessons. Or it maybe be a set of episodes that are not explicitly linked, but work together to meet overall goals of the workshop. 2.5.1.4 Curriculum A curriculum is the full set of lessons and episodes within The Carpentries, or within a Lesson Program (e.g. Software Carpentry, Data Carpentry, Library Carpentry), or within a Data Carpentry domain (e.g. Data Carpentry Social Science, Data Carpentry Geospatial). The resources within a curriculum should meet overall goals and match the audience of the domain, Lesson Program, or The Carpentries. 2.5.2 The I-We-You model Gradual release of responsibility Thinking aloud (I do) Provide scaffoding (We do) – think-pair-share, use this to identify misconceptions During the you do, move around, ask for their thinking aloud, listen to their thinking, identify misconceptions. Limitations teach to the mean. 2.6 Collaborative lesson design We transpose the model of open-source software development to collaborative lesson development. "],
["community-development.html", "Chapter 3 Community development", " Chapter 3 Community development What are the roles in the development process and what expertise should each of these have CAC Authors Reviewers - outside people who along with CAC will give feedback Maintainers How to run Maintainer onboarding Pilot instructors Instructors How to onboard existing instructors How to recruit new instructors from the domain When to put these roles in place How many people we need in these roles What are expectations for things like geographical diversity, career levels, diversity of perspectives, etc. "],
["how-to-decide-what-to-teach.html", "Chapter 4 How to decide what to teach?", " Chapter 4 How to decide what to teach? Understanding your target audience Learner profiles Determining scope (thinking of where the learners start and where they will end after the workshop) Learning pathways (where this lesson fits in and what it leads to) How to identify the core competencies you want to teach "],
["learning-objectives-and-formative-assessment.html", "Chapter 5 Learning objectives and formative assessment", " Chapter 5 Learning objectives and formative assessment How to write learning objectives What is Bloom’s taxonomy? How to use it? How to assess learner’s current Bloom level? Where do we want to bring them? Our lessons are mostly targeted for knowledge, understanding and applications stages. Setting constraints for where we want to build our lessons. Use action words for writing learning objectives How to write key points and questions Using learning objectives to define / plan challenges (“exercise about X, including XYZ concepts”) Splitting lessons into episodes and into smaller concept chunks (between exercises) Organize learning objectives and split into related groups (lessons and episodes) How to identify the size of a concept to teach Make a list of out of scope material - this can be used for documenting for “how to say no” aspect of being a maintainer Get external links for these things "],
["technological-introductions.html", "Chapter 6 Technological introductions", " Chapter 6 Technological introductions How to write Markdown How to write RMarkdown GitHub &amp; GitHub workflow (issues → PRs, who merges, how to have conversations) Lesson template - link to full documentation Creating new lesson or working with existing lesson Cheat-sheets from lesson example for syntax and page building Social aspects of Carpentries lesson dev on GitHub Social infrastructure - Maintainers, staff, CAC (roles of) "],
["assembling-the-lesson.html", "Chapter 7 Assembling the lesson 7.1 Picking a dataset 7.2 Formatting the dataset for teaching 7.3 Overview 7.4 Designing exercises 7.5 The different types of exercises", " Chapter 7 Assembling the lesson Picking a dataset Formatting a dataset to make it a teaching dataset How to write exercises (you) Different types of exercises and why / how to use them How to test exercises for correct level How to space exercises Writing the live code (we) What to write for instructor notes Writing the narrative around the code (I) How to evaluate lesson drafts for expert blind spot, correct leveling and scope Issue Bonanza (limited - CAC?) Clean-up (authors and staff) Put workshop page together We now have the alpha version of the lesson. (?) 7.1 Picking a dataset The dataset is a critical element of The Carpentries lessons. It needs to be chosen carefully and meet the following criteria. Use a single dataset – Workshops are domain-specific and the same dataset should be used across all lessons that are part of the same workshop. When developing a lesson that is not part of a standalone workshop, we encourage you to choose a dataset that is already in use in one of the workshops. If needed, you may want to create subsets of the main dataset that can include modifications. For instance, to illustrate the principles of tidy data in the Data Carpentry Ecology Spreadsheet lesson, messy spreadsheets are created from the original dataset. They use the same variables and observation types as the original dataset. Whenever possible, create these derived datasets using scripts rather than by hand, so they can be regenerated if the original dataset changes. The dataset should be released under a CC0 license – Copyright laws and laws governing use and sharing of data and databases vary among countries. The Creative Commons Zero license is designed to allow unrestricted use and sharing of data universally. The CC0 license allows the development of lessons around the dataset and modification of the dataset to suit our teaching needs. The datasets should be deposited in a public repository – We typically use Figshare. If you choose another option, make sure that the repository where the data is archived should have the following features: a DOI link points to an overview of the dataset pre-registration of the DOI all files can be downloaded directly as an archive (e.g., zip file) with a persistent link each file can be downloaded directly with a persistent link the repository supports versioning The dataset should be real and represent what researchers in the field encounter – Our workshops should provide an authentic experience. The datasets used as examples in the lessons should be based on real research datasets, and be of sufficient complexity that they are representative of the type of dataset that learners would encounter in their own research. Authors of the dataset should be identifiable, acknowledged, and there should be a link to the original source for the data – Even though the dataset we use in the lessons are released under a CC0 license, we want to acknowledge the authors of the dataset and link to the research projects based on the data we use. The dataset should be large enough – It should represent a real challenge that highlights the power and usefulness of the tools covered in the lessons. The dataset should be larger than what would be easy to analyze and manipulate in a spreadsheet program. For instance, the main Data Carpentry Ecology lesson dataset has ~35,000 rows. The dataset should be complex enough to ask interesting questions – Each observation should have at least 4-5 variables for each observations. These variables should be of a few different data types (at least continuous, discrete, integers, real numbers; and depending on the domain, include more specialized data types such as date/time, GPS coordinates, unstructured text, etc.) The motivation for study and the protocol for data collection should be understable without much context – We have limited time in our workshops to cover the technical skills we want to teach. It should not take long to explain learners what the data is about, how it was collected, and interesting questions that can be asked from it. The dataset should be relevant in different geographies and cultural contexts – Our workshops are taught to learners from diverse cultural backgrounds. The dataset should be understood without much context or pre-requiste knowledge to find it compelling. There should be clear and comprehensive metadata – The metadata should include a description of the data, and covers what is included in each column, how it was measured, and the unit in which it is reported. Overall, datasets we use in our teaching examples should be examples of publicly deposited data suitable for research re-use. Learners should be able to use these datasets as examples and guides for their own research data that they would like to publish and make available to the community. 7.2 Formatting the dataset for teaching A possible challenge when using research datasets for teaching is that the dataset can include complexity that make teaching more difficult. While it is important that the dataset provides an authentic experience to learners, you may want to consider simplifying it or doing some initial data cleaning and wrangling to make teaching easier. For instance, you may want to edit the dataset such that missing values are parsed as such when they are imported in R using the default values of the function used (e.g., readr::read_csv() considers empty cells and “NA” as default values for missing data). You may also want to consider removing data leading to errors or warnings during parsing, columns with data types that are not relevant for the learning objectives of the workshops, or variables for which the protocol used is difficult to explain. When preparing a dataset for teaching, aim to find the balance between providing an authentic experience to learners while keeping complexity low to limit distractions from the learning objectives. Depending on the lesson’s goals, it might also be interesting to include several versions of the datasets that have undergone various levels of processing. At the beginning of the lesson, you can provide clean and well organized dataset, while later you can introduce more complexity and teach how to handle it to generate the cleaner version of the data. Don’t introduce too many (no more than 3) versions of the datasets in your lessons, as dealing with many files and remembering their differences can become challenging for the learners. 7.3 Overview Carpentries workshops last two full days. Generally workshops run from 9am to 5pm, with 30-minute breaks in the morning and in the afternoon, and an hour lunch break, leaving 6 hours for instruction. Carpentries lessons are therefore designed to be taught in 1.5, 3 or 6 hours. Having long and regular breaks are needed to pace the instruction, and allow learners to remain focused and engaged. Lessons are divided into episodes. Each episode should: be designed to last 15-30 minutes; limit cognitive load by introducing at most 7(\\(\\pm\\) 2) new concepts (3 to 5 concepts preferred); include at least one to three exercises that let learners practice the concepts covered in the episode. 7.4 Designing exercises Once the learning objectives for the lesson and each episode have been identified, you can start designing exercises that provide learners an opportunity to practice the skills outlined in the learning objectives. The Bloom taxonomy level of the learning objectives help frame how much information should be provided to the learners to be able to complete the exercise and the type of exercise. Writing the exercises before writing the content of the lesson ensures that the lesson will remain focused, and can reveal concepts needed to solve the exercises that were not previously considered. Starting with two to four exercises you want learners to be able to complete on their own at the end of the training, will help you identify the skills they need to acquire. Creating this list of skills will guide you in assembling your learning objectives. This list, in combination with the learners’ profiles, and the time you have available in your training, will help you identify the prerequisite skills for the audience of the workshop, and determine at which level of the Bloom taxonomy the learning objectives need to be written. This approach is “meet your learners where they are”. [FIXME: this paragraph might belong better to the learning objective section]. Identifying what the final exercises look like, and the skill they require, will also help you create the narrative for your lessons. The final exercises should be designed such that the learners can understand from the beginning of the lesson what they are working towards. The intermediate exercises can then be designed to build the skills and confidence learners need to be able to solve the final exercises. While lessons should include exercises that are direct applications of the skills covered in the instructions, at least half of the exercises should provide an opportunity for learners to integrate these new skills with skills covered earlier in the lesson. Learning is reinforced when Instructors explicitly point out how the skills seen in earlier parts of the lesson are being integrated to solve the exercises. Exercises in Carpentries lessons are a form of formative assessment. They help learners further their learning by having a chance to put into practice the skills being taught. They also help Instructors monitor the level of understanding in the classroom, and potentially catch misconceptions in the learner’s mental models that can be corrected early on. 7.5 The different types of exercises 7.5.1 Multiple Choice Questions Multiple choice questions can be an useful tool in formative assessment if the incorrect answers help you identify misconceptions. Designing MCQs with informative distractors takes time. It can also be challenging to identify useful distractors a priori (expert blindspot), appropriate answers for the MCQ may be prompted by teaching experience and may need to be refined. Don’t test for too many concepts at once. Ask learners if they came up with other solutions, or thought of other ways of approaching the problem (that end up not working). iris %&gt;% filter(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% select(Species, Petal.Width) iris %&gt;% select(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) %&gt;% filter(Species, Petal.Width) iris %&gt;% select(Species, Petal.Width) %&gt;% filter(Species == &quot;setosa&quot; &amp; Petal.Length &gt; 1.5) The distribution of the answers can also help you strategize how to address the misconceptions. 7.5.2 Parsons Problem 7.5.3 Fill in the blanks 7.5.4 Switch the dataset 7.5.5 Use the concept in a different context "],
["the-lesson-life-cycle.html", "Chapter 8 The lesson life-cycle 8.1 Overview 8.2 Pathway for community-developed lessons", " Chapter 8 The lesson life-cycle Definitions of alpha, beta, 1.0 Alpha: The stage that it is in the first time it is taught. (in house) Beta: The stage that it is in after the pilots and clean-up. (wider community) pre-release: The stage that it is in after initial publication. (anyone) stable: Announcements letting the community know that the lesson is being prepared for release and what that means Advertising for Bug BBQ Bug BBQ How to organize for, how to schedule Communications (when and how to announce) Prep (communicating with maintainers about the process) Facilitating communications during the actual event (real time communications, issue assignments, avoiding duplication of work) Clean-up (maintainers, staff, authors) Lesson release checklist Pre-Release Release How to communicate about a release How to do the release in Zenodo Move on website to different category 8.1 Overview Community-developed lessons Lessons with grant support 8.2 Pathway for community-developed lessons Overview of the lesson release timeline If you have an idea for a lesson that would be a good fit for The Carpentries, you first need to check if there are not already existing efforts to develop lessons on the same topic that you could join. The first draft (Pre-Alpha) of a lesson is usally written by an individual or a small group of people. From this first draft, the original authors organize a pilot workshop, and improve the content of the lessons based on the feedback from learners and co-instructors. They go through this iterative process a few times to bring the lesson where it is ready to be peer-reviewed by members of The Carpentries. After that, the lesson should be developed enough that people not involved in initial development efforts can teach it and contribute to it (Beta). After about six months in this stage, the lesson is mature enough and documented enough so that anyone interested can teach it and is officially released. The Pre-Alpha and Alpha development stages should focus on the content of the lesson: What to teach? How to teach it (which exercises, in which order should the concepts be introduced)? In the Beta stage, development efforts should focus on documenting the lesson, so that any Instructor familiar with the concepts covered in the lesson can understand the design of the lesson. 8.2.1 The blueprint (lesson proposal) If you have an idea for a lesson you think would be appropriate for The Carpentries, submit a proposal to the proposals repository in the Carpentries Lab organization following our template. The Curriculum Development Team will assess the fit of the proposed lesson, check for possible overlap with other efforts, and assign an Editor. If you have questions before submitting your proposal you may contact the Curriculum Development Team. The Curriculum Development Team and the Editor will work with you on your proposal. Once your proposal is accepted, we will publish the revised version of your proposal on The Carpentries websites. Community members who wish to join the proposal or support it in other ways will be able do so. The Editor for your lesson will provide guidance during the lesson development process, answer questions that may arise during the development, and coordinate the review process for your lesson. 8.2.2 The assembly (Early development, “Pre-Alpha”) We will create or transfer your repository to the GitHub Carpentries Lab organization where you will develop your lesson. We will provide you with our lesson template, and you will follow The Carpentries lesson development guidelines. During this initial development stage, your lesson will be in the “Pre-Alpha” stage. As lesson development progresses, you will report monthly to the Editor for your lesson. You will work with your handling Editor to set a date to teach the lesson for the first time. The Editor will provide general feedback on the content and structure of the lesson, and ensure that it is ready to be taught. 8.2.3 The sanding (field test, “Alpha”) Once the lesson is ready to be taught for the first time, it will enter the “Alpha” stage. Field-testing a lesson is a good opportunity to receive and incorporate feedback from learners, Instructors, and Developers who can compare their expectations to the reality. The initial feedback gathered during the first time a lesson is taught is really important. The Carpentries Assessment Team will work with you to develop surveys to gather feedback from your learners, helpers, and instructors. The Curriculum Development Team and the Editor for the lesson will review the feedback with you, and help you decide how to incorporate this feedback in your lesson. The Carpentries Community Manager will make an announcement that a new “Alpha” lesson is available to contribute to and can be taught by instructors interested in early-adoption of the lesson. These early workshops are also a good time for Instructors not involved in the development process to teach these lessons. They can provide a fresh perspective and useful feedback on the content of the lessons. After a few iterations of teaching and integrating feedback (and at least 2 early workshop pilots), you will let the Carpentries Editor know that your lesson is ready to be reviewed. The Editor will select 2-3 reviewers within The Carpentries community with teaching experience and/or appropriate domain expertise, who will provide an open and friendly review of the lesson. After incorporating feedback and comments from the reviewers, your lesson will be badged “Reviewed by the Carpentries Community” and will be listed on our websites as such. During this process, you will have the possibility to include a short paper describing your lesson in the GitHub repository and have your lesson considered for publication in JOSE, the Journal of Open Science Education. Once your lesson has gone through the peer-review process and has been approved by the Editor, we will create an official Zenodo release for it, and the lesson will enter the “Beta” stage. 8.2.4 The polishing (“Beta”) The “Beta” stage lasts approximately 6 months. During this time, members of The Carpentries community can teach it and contribute to the content of the lesson. Around the 4th month in this stage, you will organize a “Lesson Polishing” event (aka Bug BBQ). The main goal of this phase of the lesson development is to develop the documentation needed to ensure that people who have not contributed to the initial development efforts of the lesson have enough information to teach it effectively. After a final check from one of The Carpentries’ Editors, we will create a stable release for the lesson that will be listed on our website. Anyone in our community, including local Carpentries communities, will be able to use the lesson in their workshops or meetups. 8.2.5 The stable lesson T We will generate new releases every 6 months. "],
["pilots-and-feedback.html", "Chapter 9 Pilots and Feedback", " Chapter 9 Pilots and Feedback How to run a pilot? How to recruit people to run a pilot? Feedback from pilot transformed into issues and PRs Clean-up (authors and staff) We now have the beta version "],
["from-pre-release-to-stable.html", "Chapter 10 From pre-release to stable", " Chapter 10 From pre-release to stable Workshops Organizing workshops at different institutions (staff assist) Staff make sure a certain number of workshops get organized Use responses from community form to choose institutions Communicating about the costs of these workshops Clean-up based on feedback staff works with maintainers and authors to put in these issues and convert to PRs Communication point with maintainers about release deadline and what needs to be done before then Dedicated time from staff to be available on slack to help maintainers go through issues and review prs Release "],
["maintenance.html", "Chapter 11 Maintenance", " Chapter 11 Maintenance How often to do releases Maintenance releases, as needed but at least every 3 months Big releases, once a year How to coordinate lesson releases How to communicate with Maintainers and community about lesson releases How to split development and production How to welcome and onboard new contributors, contributor guidelines "],
["the-lesson-proposal.html", "A The Lesson Proposal A.1 For all lessons A.2 For Grant-Supported lessons A.3 Transition to officially supported lesson", " A The Lesson Proposal A.1 For all lessons A short description – It should be less than 200 characters and capture the type of data and general audience for the lesson (e.g., “Tabular Data for Phylogeneticsts”, or “Data Managemnet for Digital Humanities”.) The intended audience – Who is the target audience for this lesson? (e.g. Graduate-level researchers in ecology). Duration of the lesson – How long is this lesson? 1.5, 3, 6, or 12 hours. Fit with existing Carpentries lesson – Could this lesson be added or be swapped with an existing lesson in our existing curriculum (e.g., a proposed lesson on Rmarkdown, using the Ecology dataset, could replace the episode on interacting with databases). Tools used – Describe the software, packages, libraries that will be taught in the lesson. Make it clear if any of them are not open source licensed (i.e., they are not listed on the Open Source Initiative website). Suggestions for the dataset to use – review our dataset recommendations and describe the datasets you would like to use if it’s not one that is already in use in our lessons. A brief lesson outline – For each half day of material, please describe: 3–6 concrete learning objectives. An end-of-lesson assessment exercise to demonstrate the skills participants have learned. A summary of the tools and data set(s) that will be used. A point-form learning plan A brief comparison with existing open-access lessons on the subject. Evidence of need – Summarize evidence that researchers need this lesson. This summary may include links to online discussions (mailing lists, twitter, etc) or publications (e.g., descriptions of practices that are not yet widely adopted), results of surveys, etc. Development Team – Who are the people involved? Are they certified Carpentries instructors? What is their experience developing teaching materials in general and for the Carpentries in particular? Development Plan and Timeline – The development plan must include a timeline that makes specific people responsible for specific lesson modules, commitments from specific sites to teach trial versions of the lesson, a date and location for a hackathon (if appropriate), etc. We recognize that this plan may change as lesson development progress, but the more specific it is, the more credible the proposal will be. Support – Explain who will support lesson development and how. If you have secured funding, attach details. If you have not, but intend to seek it, describe any planned or submitted funding requests. If the work is not being funded, explain how development and delivery will be supported. A.2 For Grant-Supported lessons A.3 Transition to officially supported lesson "]
]
